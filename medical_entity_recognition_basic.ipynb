{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6AKMbMbieOa+43+qGi9JD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hruthiksiva/medical-entity-recognition/blob/main/medical_entity_recognition_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SJO1NJdSGVz-"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the pre-trained NER model\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW25iataXACF",
        "outputId": "a58faf27-08cb-42dd-bbf4-d4e907c2859a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the medical text\n",
        "medical_text = \"\"\"\n",
        "The patient, Mrs. Lis Smith, was diagnosed with Type 2 diabetes and hypertension.\n",
        "She was prescribed 10mg of Lisinopril and 500mg of Metformin daily.\n",
        "The doctor recommended monitoring blood sugar levels regularly and maintaining a healthy diet.\n",
        "The follow-up appointment is scheduled for next month.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "sdmfG6VBXBaq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Apply the NER pipeline to extract entities\n",
        "raw_entities = ner_pipeline(medical_text)"
      ],
      "metadata": {
        "id": "gj_z-krwXCrp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld4KSC0bX68p",
        "outputId": "c0b8179d-4f99-4562-f9e8-dfb06e59c83e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-PER',\n",
              "  'score': 0.99855644,\n",
              "  'index': 6,\n",
              "  'word': 'Li',\n",
              "  'start': 19,\n",
              "  'end': 21},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.9966264,\n",
              "  'index': 7,\n",
              "  'word': '##s',\n",
              "  'start': 21,\n",
              "  'end': 22},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.99940634,\n",
              "  'index': 8,\n",
              "  'word': 'Smith',\n",
              "  'start': 23,\n",
              "  'end': 28},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.9652857,\n",
              "  'index': 13,\n",
              "  'word': 'Type',\n",
              "  'start': 49,\n",
              "  'end': 53},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.89916104,\n",
              "  'index': 14,\n",
              "  'word': '2',\n",
              "  'start': 54,\n",
              "  'end': 55},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.96145046,\n",
              "  'index': 29,\n",
              "  'word': 'Li',\n",
              "  'start': 111,\n",
              "  'end': 113},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.5276324,\n",
              "  'index': 30,\n",
              "  'word': '##sin',\n",
              "  'start': 113,\n",
              "  'end': 116},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.91352385,\n",
              "  'index': 38,\n",
              "  'word': 'Met',\n",
              "  'start': 135,\n",
              "  'end': 138},\n",
              " {'entity': 'I-MISC',\n",
              "  'score': 0.44034484,\n",
              "  'index': 39,\n",
              "  'word': '##form',\n",
              "  'start': 138,\n",
              "  'end': 142}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Post-process entities to handle tokenization issues\n",
        "def process_entities(entities):\n",
        "    processed_entities = []\n",
        "    current_entity = None\n",
        "\n",
        "    for entity in entities:\n",
        "        word = entity['word']\n",
        "\n",
        "        # Handle subwords starting with \"##\"\n",
        "        if word.startswith(\"##\"):\n",
        "            if current_entity:\n",
        "                current_entity['word'] += word[2:]\n",
        "                current_entity['score'] = max(current_entity['score'], entity['score'])\n",
        "        else:\n",
        "            if current_entity:\n",
        "                processed_entities.append(current_entity)\n",
        "            current_entity = entity\n",
        "            current_entity['word'] = word  # Start a new entity\n",
        "\n",
        "    if current_entity:\n",
        "        processed_entities.append(current_entity)\n",
        "\n",
        "    return processed_entities\n",
        "\n",
        "entities = process_entities(raw_entities)"
      ],
      "metadata": {
        "id": "VNLYX5cNXE_b"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Classify and modify the text\n",
        "def classify_and_modify_text(text, entities):\n",
        "    pii_labels = {'I-PER', 'I-LOC', 'I-ORG'}  # Labels considered PII\n",
        "    phi_labels = {'I-MISC'}  # Labels considered PHI\n",
        "\n",
        "    # Replace and highlight in the original text\n",
        "    modified_text = text\n",
        "    offsets = 0  # Track adjustments due to replacements\n",
        "\n",
        "    for entity in entities:\n",
        "        word = entity['word']\n",
        "        label = entity['entity']\n",
        "\n",
        "        # Determine the action based on the label\n",
        "        if label in pii_labels:\n",
        "            # Replace PII with \"[HIDDEN]\"\n",
        "            start_idx = entity['start'] + offsets\n",
        "            end_idx = entity['end'] + offsets\n",
        "            modified_text = modified_text[:start_idx] + \"[HIDDEN]\" + modified_text[end_idx:]\n",
        "            offsets += len(\"[HIDDEN]\") - len(word)\n",
        "        elif label in phi_labels:\n",
        "            # Highlight PHI by adding ** before and after\n",
        "            start_idx = entity['start'] + offsets\n",
        "            end_idx = entity['end'] + offsets\n",
        "            modified_text = modified_text[:start_idx] + \"**\" + word + \"**\" + modified_text[end_idx:]\n",
        "            offsets += len(\"**\") * 2\n",
        "\n",
        "    return modified_text"
      ],
      "metadata": {
        "id": "cpvg7UqCXH-N"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update entities with start and end positions\n",
        "for entity in entities:\n",
        "    entity_start = medical_text.find(entity['word'])\n",
        "    if entity_start != -1:\n",
        "        entity['start'] = entity_start\n",
        "        entity['end'] = entity_start + len(entity['word'])"
      ],
      "metadata": {
        "id": "-cFY4c06XKKN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the text\n",
        "modified_text = classify_and_modify_text(medical_text, entities)\n",
        "\n",
        "# Step 6: Print the modified text\n",
        "print(\"Original Text:\")\n",
        "print(medical_text)\n",
        "print(\"\\nModified Text:\")\n",
        "print(modified_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kguupsfHG6-4",
        "outputId": "77c47502-dffe-47d5-e5ff-a8b51c479524"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "The patient, Mrs. Lis Smith, was diagnosed with Type 2 diabetes and hypertension. \n",
            "She was prescribed 10mg of Lisinopril and 500mg of Metformin daily. \n",
            "The doctor recommended monitoring blood sugar levels regularly and maintaining a healthy diet. \n",
            "The follow-up appointment is scheduled for next month.\n",
            "\n",
            "\n",
            "Modified Text:\n",
            "\n",
            "The patient, Mrs. [HIDDEN] [HIDDEN], was diagnosed with **Type** **2** diabetes and hypertension. \n",
            "She was prescribed 10mg of **Lisin**opril and 500mg of **Metform**in daily. \n",
            "The doctor recommended monitoring blood sugar levels regularly and maintaining a healthy diet. \n",
            "The follow-up appointment is scheduled for next month.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6cKvKcMJE3c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}